---
title: "Chapter 8 - SNASS"
author: "Verooo"
date: "2024-09-16"
output: html_document
---

###Title: Webscraping in R Author: Bas Hofstra Version: \### 29-07-2

# Set-up

```{r}

# start with clean workspace
rm(list = ls())

# install.packages('data.table')
library(data.table)  # mainly for faster data handling
library(tidyverse)  # I assume you already installed this one!
#install.packages('httr') # we don't need this for now require(httr)
#install.packages("devtools")
require(devtools)

#install.packages("rvest")
require(rvest)
# rvest:This is the explanation the writers of the package give: “rvest is new package that makes it easy to scrape (or harvest) data from html web pages.” Seems like something we need, a package that stores information from webpages into relatively structured data that we can then query/manipulate.

#install.packages("xml2")

require(xml2)

#xml2:This is what the writers of the package say about it: “Work with XML files using a simple, consistent interface.” So we can manipulate the data scraped with rvest, using the xml2 package functions

#Note we're doing something different here. We're installing a *latest* version directly from
#GitHub This is because the released version of this packages contains some errors!
devtools::install_github("jkeirstead/scholar")

require(scholar)

library(dplyr)
#define workdirectory, note the double *backslashes* if you're on windows setwd('/yourpathhere)'



```


# Get anchor data -RU sociology

goal: get to know\
(i) who the Radboud University Department of Sociology staff is,\
(ii) what they publish with respect to scientific work, and\
(iii) who they collaborate with.


```{r, Anchor data}
soc_staff <- read_html("https://web.archive.org/web/20230528153336/https://www.ru.nl/sociology/research/staff/") #extracts the source html of a webpage

head(soc_staff)

#which object? 
class(soc_staff)

#so we need to find WHERE the table is located in the html 'inspect element' in mozilla firefox or
# view page source' and you see that everything AFTER /td in the 'body' of the page seems to be
# the table we do need

# soc_staff_0 <- soc_staff %>%
#     rvest::html_nodes("body") %>%
#     xml2::xml_find_all("//td") %>% # xml2 here looks across multiple layers/ child-elements (hence the // !!! )
#     rvest::html_text()
# 
# 
# # BETTER?
# # using html_elements to ONLY USE ONE PACKAGE (RVEST)
soc_staff <- soc_staff %>%
    rvest::html_elements("body") %>%
    rvest::html_elements ("td") %>%
    rvest::html_text()
#   
#     
# view(soc_staff)
# 
# # Get whole table at once? 
# soc_staff_1 <- soc_staff %>%
#     rvest::html_elements("body") %>%
#     rvest::html_table()

#view(soc_staff_1)
#class(soc_staff_1) # list (you can turn into a data frame to use it for further data manipulatino fromhere on)

# (fshowdf) to make output look pretty (but i probably misunderstood what exactly Jochem said)


```

# get anchor data - Leiden University - PolSci

```{r}

#do it for Leiden University 
leiden_polsci_staff <- read_html("https://www.universiteitleiden.nl/en/academic-staff/overview?pageNumber=1&faculty=social-and-behavioural-sciences&facultyinstitute=institute-of-political-science") #extracts the source html of a webpage

# div id content 
# section 
# ul class table list


leiden_polsci_staff_2 <- leiden_polsci_staff %>%
    rvest::html_elements("body") %>%
    rvest::html_elements("li")  %>%
    rvest::html_elements("strong") %>%
    rvest::html_text()

view(leiden_polsci_staff_2)



```

# sort rows into names and expertise

```{r}
#Assigning even and odd rows to 'fodd' and 'feven' (bc the output just lists the left and right side of the table interchangably)
fodd <- function(x) x%%2 != 0
feven <- function(x) x%%2 == 0

# How long are the data? nstaf beinhalted wie viele staff members es gibt ABER ist z.Z. noch falsch weil jede zweite Zeile information und kein Name ist) 
nstaff <- length(soc_staff)
nstaff

#make variable that holds all the names (aka. all the information in uneven rows)
soc_names <- soc_staff[fodd(1:nstaff)] 
# needs to be 0:nstaff instead of 1:nstaff 
  #(because the list positions start with 0 NOT with 1)
#OR insert the fODD function here 
  # because the names are actually in the uneven rows, as opposed to the SNASS example where they are in even-numbered rows 
head(soc_names)


#
soc_expertise <- soc_staff[feven(1:nstaff)]  #in the 1 until 94st number, get the even elements
head(soc_expertise)


#put the two vectors [variables in Vero's mind] (names and exptertise) together in a data frame (list) 
soc_df <- data.frame(cbind(soc_names, soc_expertise))  #columnbind those and we have a DF for soc staff!

# inspect in environment -> Data 


#inspect again, and remove the rows we don't need (check for yourself to be certain!)
delrows <- which(soc_df$soc_names == "Staff:" | soc_df$soc_names == "PhD:" | soc_df$soc_names == "External PhD:" |
    soc_df$soc_names == "Guest researchers:" | soc_df$soc_names == "Other researchers:")

soc_df <- soc_df[-delrows, ]

# inspect in environment -> Data

```

# Extract names and last names

```{r, name extraction}
# gsub   is a function that remove something and replaces it with something else

# select only last names aka. DELETE everything BEHIND a comma 
# [because the staff is listed with the last name in first place like e.g.: Müller, K. (Katrin) MSc]

  #Last name seems to be everything before the comma
soc_df$last_name <- gsub(",.*$", "", soc_df$soc_names)

# first name is everything between brackets


# stringr PACKAGE NEEDED
# install.packages("stringr")
# STILL DOESNT WORK BC NEWEST stringr PACKAGE FUCKS SHIT UP 
# INSTALL AN OLDER VERSION OF THE PACKAGE:

  # install.packages("devtools")
  # devtools::install_version("stringr", version = "1.4.1")
# soc_df$first_name <- str_extract_all(soc_df$soc_names, "(?<=\\().+?(?=\\))", simplify = TRUE)

# still does not work 
#My own attempt at fixing above mistake:
 # soc_df$first_name_TRY <-substr(soc_df$soc_names, start = "(", stop = ")")

require(tidyverse)
soc_df$first_name <- str_extract_all(soc_df$soc_names, "(?<=\\().+?(?=\\))", simplify = TRUE)

 
 view(soc_df)

```

## clean up names

```{r, clean up names }

soc_df$last_name <- gsub(" J. \\(Jansje\\) van MSc", "", soc_df$last_name)
soc_df$first_name <- tolower(soc_df$first_name)  # everything to lower!
soc_df$last_name <- tolower(soc_df$last_name)
# trimws() looses all spacing before and after (if you specify 'both') a character string
soc_df$last_name <- trimws(soc_df$last_name, which = c("both"), whitespace = "[ \t\r\n]")
soc_df$first_name <- trimws(soc_df$first_name, which = c("both"), whitespace = "[ \t\r\n]")
soc_df$soc_expertise <- trimws(soc_df$soc_expertise, which = c("both"), whitespace = "[ \t\r\n]")
soc_df$soc_names <- trimws(soc_df$soc_names, which = c("both"), whitespace = "[ \t\r\n]")
```

## make new variable (staff being from Radboud)

```{r, new variable}
# create a variable that contains a character string “radboud university” for all.
soc_df$affiliation <- "radboud university"
view(soc_df)

```

# Google Scholar Profiles and Publication

## reminder: for loops

```{r, for loop}
# The 'for loop': for every i in a vector (can be numbers, strings, etc.), say 1 to 10, you can do
# 'something'
for (i in 1:10) {
    print(i)  # So for every i from 1 to 10, we print i, see what happens!
}

# # or do something more complicated p <- rnorm(10, 0, 1) # draw 10 normally distributed numbers
# with mean 0 and SD 1 (so z-scores, essentially) plot(density(p)) # relatively, normal, right?  u
# <- 0 # make an element we can fill up in the loop below for (i in 1:10) { u[i] <- p[i]*p[i] # get
# p-squared for every i-th element in vector p print(u[i]) # and print that squared element }
```

## linking a SINGLE staff member to their google scholar link

```{r}

soc_df$gs_id <- ""  # we set an empty identifier


# using get_scholar_id()
# The function get_scholar_id needs a last name, first name, and affiliation.


require(scholar)
#downloaded function:
get_scholar_id_fix <- function (last_name = "", first_name = "", affiliation = NA)
{
  if (!any(nzchar(c(first_name, last_name))))
    stop("At least one of first and last name must be specified!")
  site <- getOption("scholar_site")
  url <- paste0(site, "/citations?view_op=search_authors&mauthors=",
                first_name, "+", last_name, "&hl=en&oi=ao")
  page <- get_scholar_resp(url)
  if (is.null(page))
    return(NA)
  aa <- httr::content(page, as = "text")
  # added by Bas Hofstra: bugfix for IDs that have a dash ("-")
  ids <- substring(aa, regexpr(";user=", aa))
  ids <- substr(ids, 1, 19) # error prone, but unsure how to solve otherwise
  # if (nchar(stringr::str_extract_all(string = aa, pattern = ";user=[[:alnum:]]+[[:punct:]]")[[1]][1]) < 18) {
  #   ids <- stringr::str_extract_all(string = aa, pattern = ";user=[[:alnum:]]+[[:punct:]]+[[:alnum:]]+[[:punct:]]")
  # } else {
  #   ids <- stringr::str_extract_all(string = aa, pattern = ";user=[[:alnum:]]+[[:punct:]]")
  # }
  if (length(unlist(ids)) == 0) {
    message("No Scholar ID found.")
    return(NA)
  }
  ids <- ids %>% unlist %>% gsub(";user=|[[:punct:]]$", "",
                                 .) %>% unique
  if (length(ids) > 1) {
    profiles <- lapply(ids, scholar::get_profile)
    if (is.na(affiliation)) {
      x_profile <- profiles[[1]]
      warning("Selecting first out of ", length(profiles),
              " candidate matches.")
    }
    else {
      which_profile <- sapply(profiles, function(x) {
        stringr::str_count(string = x$affiliation, pattern = stringr::coll(affiliation,
                                                                           ignore_case = TRUE))
      })
      if (all(which_profile == 0)) {
        warning("No researcher found at the indicated affiliation.")
        return(NA)
      }
      else {
        x_profile <- profiles[[which(which_profile !=
                                       0)]]
      }
    }
  }
  else {
    x_profile <- scholar::get_profile(id = ids)
  }
  return(x_profile$id)
}


#TRYING get_scholar_id from ONE staff member first 

# SETTING SOURCE:
#source("C:/Users/Vero/OneDrive - Radboud Universiteit/Documents/GitHub/labjournal")  
# DOES NOT WORK BUT WORKS IF YOU DEFINE FUNCTION IN THE SAME SCRIPT YOU ARE WORKINGIN 
# Put the function_fix.R in your working directory, we need this first line.
# Vero: I put the function in an R-Script and saved it in the same folder as the script I have open rn. 


get_scholar_id_fix(last_name = "tolsma", first_name = "jochem", affiliation = "radboud university")

get_profile("Iu23-90AAAAJ")  # Jochem's profile

```

### get scholar publications, citations

```{r, pubs and citations}
get_publications("Iu23-90AAAAJ")  # Jochem's pubs


get_citation_history("Iu23-90AAAAJ")  # Jochem's citation history
```

### get collaborators

```{r, collaborators}
jochem_coauthors <- get_coauthors("Iu23-90AAAAJ", n_coauthors = 50, n_deep = 1)  
# Jochem's collaborators and their co-authors!

```

## plot network of single staff member

```{r, plot}
plot_coauthors(get_coauthors("Iu23-90AAAAJ", n_coauthors = 20, n_deep = 1), size_labels = 2)  
# Doesn't look like much yet, but we'll make it prettier later.

```

# link scholar profiles of ALL STAFF

```{r, staff total scholar link, eval=FALSE, include=FALSE}
# Look throught get_scholar_id_fix(last_name, first_name, affiliation) 
# if we can find google scholar profiles of sociology staff!
for (i in 1:nrow(soc_df)) {
  
  time <- runif(1, 0, 8) # randomized request times bc scholar has a "trip switch" against spam (rate limit)
  Sys.sleep(time)
# for every number from 1 to 10 we draw one number from 0 to 8 from a uniform distribution we put
# the wrapper sys.sleep around it that we put R to sleep for the drawn number
  
  
  tryCatch({
     soc_df[i,c("gs_id")] <- get_scholar_id_fix(last_name = soc_df[i, c("last_name")], # so search on last_name of staff (third column)
                                             first_name = soc_df[i, c("first_name")],  # search on first_name of staff (fourth column)
                                             affiliation = soc_df[i,c("affiliation")]) # search on affiliation of each staff (fifth column)

    }, error=function(e){cat("ERROR :", conditionMessage(e), "\n")}) # continue on error, but print the error
  }

# remove those without pubs from the df
# seems we're left with about 34 sociology staff members!
soc_df <- soc_df[!soc_df$gs_id == "", ]
soc_df
```

## get publications (all staff)

```{r eval=FALSE, include=FALSE}
#CURRENTLY: CODE IN THIS CHUNK IS NOT RUN (change in little setting weel at the top rightof this chunk)

# gather the profiles and publications and store them in a LIST 

soc_list_profiles <- list()  # first we create an empty list that we then fill up with the for loop
soc_list_publications <- list()

for (i in 1:nrow(soc_df)) {

    time <- runif(1, 0, 10) # randomized requests? 
    Sys.sleep(time)

    # note how you call different elements in a list '[[]]', fill in the i-th element
    soc_list_profiles[[i]] <- get_profile(soc_df[i, c("gs_id")])  # Note how we call row i (remember how to call rows in a DF/Matrix) and then the associated scholar id
    soc_list_publications[[i]] <- get_publications(soc_df[i, c("gs_id")])
    soc_list_publications[[i]][, c("gs_id")] <- soc_df[i, c("gs_id")]  # note that we again attach an id
    # so both functions here call the entire profile and pubs for an author, based on google scholar ids

}
# Notice how fast the data blow up! The 34 RU sociology scholars publish ~3000 papers
soc_df_publications <- bind_rows(soc_list_publications)



```

## google scholar says NO :( (too many requests despite random requests)

-\> cannot make lists with publications and profiles as of now (evening of 17th September) :/

# continue shortly before "getting collaborators" at Chapter 8.6.4

search and find: note how soc_list_profiles

# gender from names

```{r}
# voornamenbank Maartens insitute 
# e.g. Vero:
# https://nvb.meertens.knaw.nl/naam/is/Vero

# use the concatenate function cat 
# and make a loop that just fills in the name in question in the link 

# INSERT CODE HERE 



# Last names: https://cbgfamilienamen.nl/nfb/
```

# custom functions chunk for functions to run later on

```{r}
fpackage.check <- function(packages) {
    lapply(packages, FUN = function(x) {
        if (!require(x, character.only = TRUE)) {
            install.packages(x, dependencies = TRUE)
            library(x, character.only = TRUE)
        }
    })
}

fsave <- function(x, file = NULL, location = "./data/processed/") {
    ifelse(!dir.exists("data"), dir.create("data"), FALSE)
    ifelse(!dir.exists("data/processed"), dir.create("data/processed"), FALSE)
    if (is.null(file))
        file = deparse(substitute(x))
    datename <- substr(gsub("[:-]", "", Sys.time()), 1, 8)
    totalname <- paste(location, datename, file, ".rda", sep = "")
    save(x, file = totalname)  #need to fix if file is reloaded as input name, not as x. 
}

fload <- function(filename) {
    load(filename)
    get(ls()[ls() != "filename"])
}

#install.packages("kableExtra")
library(kableExtra)

fshowdf <- function(x, ...) {
    knitr::kable(x, digits = 2, "html", ...) %>%
        kableExtra::kable_styling(bootstrap_options = c("striped", "hover")) %>%
        kableExtra::scroll_box(width = "100%", height = "300px")
}
```

# Open alex

```{r}
# SEE SUNBELT WEBSITE: Attributes tab 
# if you put html from open alex api into the read html function then you need to replace any spaces with a + symbol

# get JSON package so it can read the JSON object 


```

# R Package openalexR (using r wrapper )

```{r}
# make JSON object easier to use

#install.packages("openalexR")
library(openalexR)

options(openalexR.mailto = "palmtreesdude@gmail.com")

df <- oa_fetch(entity= "author", search = "Jochem Tolsma")

fshowdf(df)

#second affiliation ofJochem is lost when using this wrapper 
# SOMETIMES INFORMATION CAN GET LOST 
df_papers <- oa_fetch(entity = "works", author.id = df$id)
df_papers$author[1] # selecting first item in column "author" which in this case is a full data base 
# OUtput gives us id from author AND CO-author 


# To prevent doubles for authors that have common names we can use MULTIPLE FILTERS: eg. institution Radboud University and country NL and so on... 

# find institution ids first to then filterforinstitutions:
oa_fetch(entity = "institutions", search = "Radboud University")
#output will show id: https://openalex.org/I145872427	 for Radboud University Nijmegen

# in code on Jochems in line 162 file title 45 publicationsOpenAlex.rmd

oa_fetch(entity= "author", search = "Jochem Tolsma", affiliations.institution.id = "https://openalex.org/I145872427")
#putput already has a lot of information on Jochem 


# NEXT: find all papers Jochem wrote 

oa_fetch (entity = "works", author.id = 'https://openalex.org/A5087380803')
 # id is the author id  from somewhere prior in Jochems script 


```

## Adjacency matrix for 4 authors

```{r}
packages <- c("tidyverse", "scholar", "openalexR", "rvest", "jsonlite")
fpackage.check(packages)
# make adjacency matrix for these four people 

#Jochem tolsma
# Tom van de Meer
# Maurice Gesthuizen 
# Michael Savelkoul  

# What data do we need? 
  # Authors, University, works, and co-authors 
  # All in one data frame 


# Jochem Tolsma 
df_jochem <- oa_fetch(entity= "author", search = "Jochem Tolsma", affiliations.institution.id = "https://openalex.org/I145872427")

fshowdf(df_jochem)

# Maurice Gesthuizen
df_maurice <- oa_fetch(entity= "author", search = "Maurice Gesthuizen", affiliations.institution.id = "https://openalex.org/I145872427")

fshowdf(df_maurice)

# Michael Savelkoul
df_michael <- oa_fetch(entity= "author", search = "Michael Savelkoul", affiliations.institution.id = "https://openalex.org/I145872427")

fshowdf(df_michael)

# Tom van der Meer
df_tom <- oa_fetch(entity= "author", search = "Tom van der Meer", affiliations.institution.id = "https://openalex.org/I145872427")[1,]

fshowdf(df_tom)
#if output two id's: make decision rule
# here savest bet isto collect all 5 tom's there are bc we make a matrix
# if we want to look at citation scores, we have to probably only take the first id 

#one vector with all authors 
all_authors <- rbind(df_jochem, df_maurice, df_michael, df_tom)

```

### works

```{r}
# Jochem's work 
df_works_jochem <- oa_fetch (entity = "works", author.id = "https://openalex.org/A5087380803")

# Maurice Gesthuizen
df_works_maurice <- oa_fetch (entity = "works", author.id = "https://openalex.org/A5007673492")

# Michael Savelkoul
df_works_michael <- oa_fetch (entity = "works", author.id = "https://openalex.org/A5048988743")

# Tom van der Meer
df_works_tom <- oa_fetch (entity = "works", author.id = "https://openalex.org/A5010780363")


# vector with all works
all_works <- rbind(df_works_tom, df_works_michael, df_works_maurice, df_works_jochem)


```

## make matrix

```{r}
# ALT + MINUS make the ARROWS <- 
# STR + SHIFT + M makes the %>% 
# STR + SHIFT + C can make a comment of multiple lines you highlighted

# use column 'author' from works overview 
# 4x4 matrix
# decide for which time period 
  # 2 waves of 4 years: 2019-2023, 2014-2018 
  # select papers with publication date in this date frame 
    # publication year variable 

# make selection of dates
#wave 1
works_wave1 <- all_works %>% filter(publication_year >= 2014 & publication_year <= 2018)
#wave 2
works_wave2 <- all_works %>% filter(publication_year >= 2019 & publication_year <= 2023)

# make empty 4x4 matrix
  # name each row and column with the identifiers of scholars

matrix_wave1 <- matrix(0, nrow = 4, ncol = 4)

rownames(matrix_wave1) <- c("https://openalex.org/A5087380803", "https://openalex.org/A5007673492", "https://openalex.org/A5048988743", "https://openalex.org/A5010780363")

colnames(matrix_wave1)<- c("https://openalex.org/A5087380803", "https://openalex.org/A5007673492", "https://openalex.org/A5048988743", "https://openalex.org/A5010780363")

print(matrix_wave1)


# loop through works

  # row 1: 
    # works[1,] # in the loop it would be 'i'

  # output shows we want information from column"au_id"
    works_wave1[1,]$author[[1]]$au_id
    
    # output: first listed is the SENDER
    ego <- works_wave1[1,]$author[[1]]$au_id[1]
    
    # the RECEIVERS are everyone BUT the ego aka. the first one
    alters <- works_wave1[1,]$author[[1]]$au_id[-1]
    
  # CHECK if ego is part of authors 
  # Filter only the author who are part of the other authors 
    # Check if author is in list 
      # t[t %in% authors]
  

  matrix_wave1[ego,alters] <- 1
  #works_wave1[ego,alters] <- works_wave1[ego,alters] + 1 



# Create a 4x4 matrix filled with 0's
matrix_wave2 <- matrix(0, nrow = 4, ncol = 4)

rownames(matrix_wave2) <- c("https://openalex.org/A5087380803", "https://openalex.org/A5007673492", "https://openalex.org/A5048988743", "https://openalex.org/A5010780363")

colnames(matrix_wave2)<- c("https://openalex.org/A5087380803", "https://openalex.org/A5007673492", "https://openalex.org/A5048988743", "https://openalex.org/A5010780363")

print(matrix_wave2)

# old code from week 2 
# matrix_graph <- graph.adjacency(matrix_wave1)

# print(matrix_graph)
```
